{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4863e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac14e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d71a88",
   "metadata": {},
   "source": [
    "#STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13dab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class State(BaseModel):\n",
    "    query: str = Field(description=\"User question\")\n",
    "    category: str = Field(description=\"Category the question belongs to\")\n",
    "    sentiment: str = Field(description=\"Sentiment of the input query\")\n",
    "    response: str = Field(description=\"Final response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c204336",
   "metadata": {},
   "source": [
    "#Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0332915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "class Nodes:\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "\n",
    "    async def categorization_node(self, state: State)->State:\n",
    "        \"\"\"\n",
    "        Categorize the customer query into Technical, Billing, or General.\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"Categorize the following customer query into one of these categories: \"\n",
    "        \"Technical, Billing, General. Query: {query}\"\n",
    "        )\n",
    "\n",
    "        chain = prompt | self.llm\n",
    "        category = await chain.ainvoke(state.query)\n",
    "        return category\n",
    "    \n",
    "    async def sentiment_analyser(self, state: State)->State:\n",
    "        \"\"\"\n",
    "        Analyze the sentiment of customer query as Positive, Negative or Neutral\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "             \"Analyze the sentiment of the following customer query. \"\n",
    "        \"Respond with either 'Positive', 'Neutral', or 'Negative'. Query: {query}\"\n",
    "        )\n",
    "        chain = prompt | self.llm\n",
    "        sentiment = await chain.ainvoke(state.query)\n",
    "        return  sentiment\n",
    "    \n",
    "    async def technical_query_handler(self, state: State)->State:\n",
    "        \"\"\"\n",
    "        Provide technical support response to the query\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "             \"Provide a technical support response to the following query: {query}\"\n",
    "        )\n",
    "\n",
    "        chain = prompt | self.llm\n",
    "        response = await chain.ainvoke(state.query)\n",
    "        return response\n",
    "    \n",
    "    async def billing_handler(self, state: State)->State:\n",
    "        \"\"\"Provide a billing support response to the query.\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"Provide a billing support response to the {query}\"\n",
    "        )\n",
    "        chain = prompt | self.llm\n",
    "        response = await chain.ainvoke(state.query)\n",
    "        return response\n",
    "    \n",
    "    async def general_query_handler(self, state: State)->State:\n",
    "        \"\"\"\n",
    "        Provide support for general cuatomer query\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "             \"Provide a general support response to the following query: {query}\"\n",
    "        )\n",
    "        chain = prompt | self.llm\n",
    "        response = await chain.ainvoke(state.query)\n",
    "        return response\n",
    "    \n",
    "    async def query_escalate(self)-> State:\n",
    "        \"\"\"\n",
    "        Escalate the query to a human agent due to negative sentiment.\n",
    "        \"\"\"\n",
    "        return \"The query has been escalated tp human agent due to negative sentiment.\"\n",
    "    \n",
    "    def router(state:State):\n",
    "        \"\"\"\n",
    "        Routes the state messages to proper nodes\n",
    "        \"\"\"\n",
    "        if state.sentiment == \"Negative\":\n",
    "            return \"query_escalate\"\n",
    "        elif state.category == \"Technical\":\n",
    "            return \"technical_query_handler\"\n",
    "        elif state.category == \"general\":\n",
    "            return \"general_query_handler\"\n",
    "        else:\n",
    "            return \"billing_handler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee27913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class WorkFlow:\n",
    "    def __init__(self):\n",
    "        self.graph_builder = StateGraph(State)\n",
    "        self.nodes = Nodes(llm=llm)\n",
    "\n",
    "    def customer_support_graph(self):\n",
    "        \"\"\"\n",
    "        Provides all the nodes and edges to create a graph\n",
    "        \"\"\"\n",
    "        self.graph_builder.add_node(\"categorization_node\", self.nodes.categorization_node)\n",
    "        self.graph_builder.add_node(\"sentiment_analyser\", self.nodes.sentiment_analyser)\n",
    "        self.graph_builder.add_node(\"technical_support\", self.nodes.technical_query_handler)\n",
    "        self.graph_builder.add_node(\"general_support\", self.nodes.general_query_handler)\n",
    "        self.graph_builder.add_node(\"billing_support\", self.nodes.billing_handler)\n",
    "        self.graph_builder.add_node(\"escalate\", self.nodes.query_escalate)\n",
    "\n",
    "        self.graph_builder.add_edge(START, \"categorization_node\")\n",
    "        self.graph_builder.add_edge(\"categorization_node\", \"sentiment_analyser\")\n",
    "        self.graph_builder.add_conditional_edges(\n",
    "                \"sentiment_analyser\",\n",
    "                self.nodes.router,\n",
    "            {\n",
    "               \"query_escalate\": \"escalate\",\n",
    "               \"billing_handler\": \"billing_support\",\n",
    "               \"general_query_handler\": \"general_support\",\n",
    "               \"technical_query_handler\": \"technical_support\"\n",
    "            }\n",
    "        )\n",
    "        self.graph_builder.add_edge(\"escalate\", END)\n",
    "        self.graph_builder.add_edge(\"billing_support\", END)\n",
    "        self.graph_builder.add_edge(\"general_support\", END)\n",
    "        self.graph_builder.add_edge(\"technical_support\", END)\n",
    "\n",
    "        return self.graph_builder\n",
    "\n",
    "    \n",
    "    def setup_graph(self):\n",
    "        \"\"\"\n",
    "        Builds the graph upon calling\n",
    "        \"\"\"\n",
    "        graph = self.graph_builder.compile()\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea3d2750",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(query: str):\n",
    "    \"\"\"\n",
    "    Starts the workflow with query and provides response\n",
    "    \"\"\"\n",
    "    graph = WorkFlow().setup_graph()\n",
    "    response = await graph.ainvoke(query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6578b105",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph must have an entrypoint: add at least one edge from START to another node",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m      6\u001b[39m query = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEnter your query: \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m result = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCategory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Files\\GitHub_Materials\\GenAI_Agents\\.venv\\Lib\\site-packages\\nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Files\\GitHub_Materials\\GenAI_Agents\\.venv\\Lib\\site-packages\\nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.13.3-windows-x86_64-none\\Lib\\asyncio\\futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.13.3-windows-x86_64-none\\Lib\\asyncio\\tasks.py:304\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    302\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    303\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Starts the workflow with query and provides response\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     graph = \u001b[43mWorkFlow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m graph.ainvoke(query)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mWorkFlow.setup_graph\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msetup_graph\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     40\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m    Builds the graph upon calling\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     graph = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgraph_builder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m graph\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Files\\GitHub_Materials\\GenAI_Agents\\.venv\\Lib\\site-packages\\langgraph\\graph\\state.py:618\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, cache, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    615\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    617\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    622\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    627\u001b[39m output_channels = (\n\u001b[32m    628\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    629\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    635\u001b[39m     ]\n\u001b[32m    636\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Files\\GitHub_Materials\\GenAI_Agents\\.venv\\Lib\\site-packages\\langgraph\\graph\\graph.py:277\u001b[39m, in \u001b[36mGraph.validate\u001b[39m\u001b[34m(self, interrupt)\u001b[39m\n\u001b[32m    274\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound edge starting at unknown node \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m START \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    278\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGraph must have an entrypoint: add at least one edge from START to another node\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    279\u001b[39m     )\n\u001b[32m    281\u001b[39m \u001b[38;5;66;03m# assemble targets\u001b[39;00m\n\u001b[32m    282\u001b[39m all_targets = {end \u001b[38;5;28;01mfor\u001b[39;00m _, end \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._all_edges}\n",
      "\u001b[31mValueError\u001b[39m: Graph must have an entrypoint: add at least one edge from START to another node"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    query = input(\"Enter your query: \")\n",
    "    result = asyncio.run(main(query))\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Category: {result['category']}\")\n",
    "    print(f\"Sentiment: {result['sentiment']}\")\n",
    "    print(f\"Response: {result['response']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577113bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
