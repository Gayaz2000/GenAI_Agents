{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "991bedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9380220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, List\n",
    "\n",
    "class StateFlow(TypedDict):\n",
    "    text : str\n",
    "    classification: str\n",
    "    entities: List[str]\n",
    "    summary : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44a89f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "class GroqLLM:\n",
    "    def __init__(self, model_name: str = \"deepseek-r1-distill-llama-70b\"):\n",
    "        self.model_name = model_name\n",
    "        self.llm = None\n",
    "    \n",
    "    def load_groq_llm(self, temperature: float = 0, max_tokens: int =1000):\n",
    "        \"\"\"loads required groq model\"\"\"\n",
    "        try:\n",
    "            if \"llama\" in self.model_name:\n",
    "                self.llm = ChatGroq(model=\"llama3-70b-8192\")\n",
    "                #return llm\n",
    "            elif \"deepseek\" in self.model_name:\n",
    "                self.llm = ChatGroq(model=\"deepseek-r1-distill-llama-70b\")\n",
    "                #return llm\n",
    "            elif \"gemma\" in self.model_name:\n",
    "                self.llm = ChatGroq(model=\"gemma2-9b-it\")\n",
    "                #return llm\n",
    "            elif \"qwen\" in self.model_name:\n",
    "                self.llm = ChatGroq(model=\"qwen-qwq-32b\")\n",
    "            else:\n",
    "                raise f\"model name was not given\"\n",
    "            return  self.llm\n",
    "        except Exception as e:\n",
    "            raise f\"Error occured as: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b011e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "class AgentNodes:\n",
    "    def __init__(self):\n",
    "        self.llm = GroqLLM().load_groq_llm()\n",
    "        #self.state = StateFlow\n",
    "\n",
    "\n",
    "    def classification_node(self, state: StateFlow):\n",
    "        \"\"\"Classifies input text as News, Blog, Research Paper, or Other.\"\"\"\n",
    "        template = \"\"\"\n",
    "            Classify the following text into one of the categories: News, Blog, Research, or Other.\n",
    "            \\n\\nText:{text}\n",
    "            \\n\\nCategory:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template= template\n",
    "        )\n",
    "        message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
    "        classification = self.llm.invoke([message]).content.strip()\n",
    "        return {\"classification\": classification}\n",
    "\n",
    "    \n",
    "    def entity_extraction_node(self, state: StateFlow):\n",
    "        \"\"\"Extract all the entities (Person, Organization, Location) from the text\"\"\"\n",
    "        template = \"\"\"\n",
    "            Extract all the entities (Person, Organiztion, Location) from the following text, \n",
    "            provide result in the form of comma-separated values in a list.\n",
    "            \\n\\nText: {text}\n",
    "            \\n\\nEntities:  \n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template= template\n",
    "        )\n",
    "        message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
    "        entities = self.llm.invoke([message]).content.strip().split(\", \")\n",
    "        return {\"entities\": entities}\n",
    "    \n",
    "    def summary_node(self, state: StateFlow):\n",
    "        \"\"\"Summarize the text in on short sentence\"\"\"\n",
    "        template = \"\"\"\n",
    "            Summarize the following text into one short sentence\n",
    "            \\n\\nText: {text}\n",
    "            \\n\\nSummary:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template= template\n",
    "        )\n",
    "        message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
    "        summary = self.llm.invoke([message]).content.strip()\n",
    "        return {\"summary\": summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba8d3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import display, Image\n",
    "\n",
    "class GraphBuilder:\n",
    "    def __init__(self):\n",
    "        self.nodes = AgentNodes()\n",
    "        self.graph_builder = StateGraph(StateFlow)\n",
    "        self.text_analysis_graph()  # Ensure edges and nodes are added\n",
    "\n",
    "    def text_analysis_graph(self):\n",
    "        \"\"\"Creates the flow for the graph\"\"\"\n",
    "        self.graph_builder.add_node(\"Text Classification\", self.nodes.classification_node)\n",
    "        self.graph_builder.add_node(\"Entities Extraction\", self.nodes.entity_extraction_node)\n",
    "        self.graph_builder.add_node(\"Text Summary\", self.nodes.summary_node)\n",
    "\n",
    "        self.graph_builder.add_edge(START, \"Text Classification\")\n",
    "        self.graph_builder.add_edge(\"Text Classification\", \"Entities Extraction\")\n",
    "        self.graph_builder.add_edge(\"Entities Extraction\", \"Text Summary\")\n",
    "        self.graph_builder.add_edge(\"Text Summary\", END)\n",
    "\n",
    "    def setup_graph(self):\n",
    "        \"\"\"Compiles the graph\"\"\"\n",
    "        return self.graph_builder.compile()\n",
    "\n",
    "    def get_graph_image(self):\n",
    "        \"\"\"Visualizes the workflow as an image\"\"\"\n",
    "        graph = self.setup_graph()\n",
    "        display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81eb4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def get_response(text:str):\n",
    "    \"\"\"Provides response using the graph\"\"\"\n",
    "    graph = GraphBuilder().setup_graph()\n",
    "    response = await graph.ainvoke({\"text\": text})\n",
    "    return response\n",
    "\n",
    "async def get_graph():\n",
    "    \"\"\"creates workflow image\"\"\"\n",
    "    obj = GraphBuilder()\n",
    "    graph = await  obj.get_graph_image()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53f84109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Category: News\n",
      "\n",
      "Entities: ['Here are the extracted entities in the form of comma-separated values:\\n\\nOpenAI', 'GPT-4', 'GPT-3']\n",
      "\n",
      "Summary: OpenAI has announced GPT-4, a large multimodal model that achieves human-level performance on various benchmarks and is designed to be more efficient and safer than its predecessor.\n",
      "<coroutine object get_graph at 0x000001E6BEB59F20>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    text = input(\"Enter your text: \")\n",
    "    result = asyncio.run(get_response(text))\n",
    "    print(\"Classification:\", result[\"classification\"])\n",
    "    print(\"\\nEntities:\", result[\"entities\"])\n",
    "    print(\"\\nSummary:\", result[\"summary\"])\n",
    "\n",
    "    graph = get_graph()\n",
    "    print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b919eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
